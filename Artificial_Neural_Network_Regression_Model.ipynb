{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://githubtocolab.com/shanbor-kurbah/GEE-COlab-others/blob/main/Artificial_Neural_Network_Regression_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ],
      "metadata": {
        "id": "Q_rZ123Du5nv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "396i-SMOuykn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "def sigmoid_der(x):\n",
        "    return sigmoid(x)*(1-sigmoid(x))"
      ],
      "metadata": {
        "id": "CsAe7p1JvAqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Set_X=np.array([[300.0,99.0,6.8],[308.0,103.0,8.36],[329.0,110.0,9.15],[332.0,118.0,9.36]])\n",
        "X_test=np.array([[296.0,95.0,7.54],[293.0,97.0,7.8],[325.0, 112.0,8.96]])\n",
        "Training_Set_Y=np.array([0.36,0.7,0.84,0.9])\n",
        "Y_test=np.array([0.44,0.64,0.8])\n",
        "\n",
        "\n",
        "print(\"Training_Set_X : \",Training_Set_X)\n",
        "print(\"Training_Set_Y : \",Training_Set_Y)\n",
        "print(\"X_test : \",X_test)\n",
        "print(\"Y_test : \",Y_test)\n",
        "\n",
        "#2.\tInitialize the parameters with some random values.\n",
        "np.random.seed(42)\n",
        "weights1 = np.random.rand(3,3)\n",
        "weights2=np.random.rand(3,)\n",
        "bias1 = np.random.rand(1)\n",
        "bias2 = np.random.rand(1)\n",
        "#learning rate\n",
        "lr = np.random.rand()\n",
        "print(\"lr: \",lr,\"\\n\")\n",
        "print(\"weights1:\",weights1,\"\\n\")\n",
        "print(\"weights2:\",weights2,\"\\n\")"
      ],
      "metadata": {
        "id": "dxnd9JXovBOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SE to save all Squared Errors values\n",
        "SE=list()\n",
        "\n",
        "#3.Perform a feed-forward stage to propagate the input forward through the network.\n",
        "for epoch in range(len(Training_Set_X)):\n",
        "    print(\"At Epoch: \",epoch)\n",
        " # feedforward step1\n",
        "    R = Training_Set_X[epoch].dot( weights1.T) + bias1 # linear response\n",
        "    #feedforward step2\n",
        "    H = sigmoid(R)  # activation f’n\n",
        "    S=H.dot( weights2.T)+bias2  # linear response\n",
        "    # backpropagation step 1\n",
        "    Yhat=sigmoid(S)\n",
        "    error = (Yhat) - Training_Set_Y[epoch]\n",
        "    SE.append((error**2))\n",
        "\n",
        "#5.\tPrint the content of the input/output of hidden layers and output layer at the feed forward stages.\n",
        "  #input of hidden layers\n",
        "    print(\"R :\",R)\n",
        "    #the output of hidden layers\n",
        "    print(\"H1 ,H2,& H3 :\" ,H)\n",
        "   #input of output layer\n",
        "    print(\"S :\",S)\n",
        "    #the output of output layer\n",
        "    print(\"Yhat :\",Yhat)\n",
        "    print(\"Error :\",error)\n",
        "\n",
        "    #4.Preform the back-propagation algorithm using sum square error (SSE).\n",
        "    # backpropagation step 2\n",
        "    S_Si_der = sigmoid_der(S)\n",
        "    G2= (error * S_Si_der)*(H)\n",
        "    R_Si_der=sigmoid_der(R)\n",
        "   # Update weights2\n",
        "   #6.Print the content of the weight matrices after each epoch (4 epochs)\n",
        "    for i in range(len(weights2)):\n",
        "        weights2[i] -= (lr * G2[i])\n",
        "    print(\"The content of the weight2 matrices  :\\n\",weights2,\"\\n\")\n",
        "        # Update weights1\n",
        "    for i in range(len(weights1)):\n",
        "        for j in range(len(weights1[i])):\n",
        "            weights1[i][j] -= (error * S_Si_der*weights2[i]*R_Si_der[i]*Training_Set_X[epoch][j])\n",
        "\n",
        "    print(\"The content of the weight1 matrices  :\\n\",weights1,\"\\n\")\n",
        "#sum square error\n",
        "print(\"SSE:\",sum(SE))"
      ],
      "metadata": {
        "id": "IvmkSbVovDnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7.\tTest and report the result of classifying the testing examples.\n",
        "# SE2 to save all Squared Errors values\n",
        "SE2=list()\n",
        "for epoch in range(len(X_test)):\n",
        "    # feedforward step1\n",
        "    R = X_test[epoch].dot( weights1.T) + bias1 # linear response\n",
        "    #feedforward step2\n",
        "    H = sigmoid(R)  # activation f’n\n",
        "    S=H.dot( weights2.T)+bias2  # linear response\n",
        "    # backpropagation step 1\n",
        "    Yhat=sigmoid(S)\n",
        "    error = (Yhat) - Y_test[epoch]\n",
        "    SE2.append((error**2))\n",
        "#5.\tPrint the content of the input/output of hidden layers and output layer at the feed forward stages.\n",
        "    print(\"Example  :\",epoch+1)\n",
        "    print(\"The predicted chance of acceptance :\",Yhat)\n",
        "    print(\"Error :\",error)\n",
        "#sum square error\n",
        "print(\"SSE:\",sum(SE2))"
      ],
      "metadata": {
        "id": "hchzW8oSvF1M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}